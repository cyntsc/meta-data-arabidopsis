{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for preparing control data set of Genes related with the plant's defense mechanisms\n",
    "\n",
    "1.- Data where consulted and retrieved from Uniprot database based on:\n",
    "    a) 11 Gene classes previousy selected see list below)\n",
    "             Gene_Class (e.g: BAK1, FLS2, etc\n",
    "    b) Plants resource database\n",
    "    c) Reviewed: swiss-prot database\n",
    "    \n",
    "    E.g query: BAK1+plats+reviewed; cdpks plants AND reviewed:yes\n",
    "                 \n",
    "2.- Structure of the data downloaded: (In this order as tab-separated file)\n",
    "    Uniprot: Entry_name+Gene_name(primary)+Protein_names+Length\n",
    "    \n",
    "Summary: \n",
    "11 datasets where recovery on March 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cynthia/xtrome-main/notebooks'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserting 'protein class' meta-data into each of the files recovered\n",
    "### Personalized classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein predifined meta-data class\n",
      "2:BIK1\n",
      "3:CC\n",
      "4:CDPKS\n",
      "5:FLS2\n",
      "6:MAPKS\n",
      "7:NB-LRR\n",
      "8:PRR\n",
      "9:RKS\n",
      "10:RLKS\n",
      "11:TIR\n"
     ]
    }
   ],
   "source": [
    "# Preparing dictionary of classes\n",
    "dict_uniprot = {'2': 'BIK1', '3': 'CC','4': 'CDPKS', '5': 'FLS2', '6': 'MAPKS', '7': 'NB-LRR', '8': 'PRR', '9': 'RKS','10': 'RLKS', '11': 'TIR'}\n",
    "\n",
    "# Class 1: 'BAK1' is not in the dict_uniprot due it is created when initialized the Uniprot_defense_related.csv file \n",
    "print('Protein predifined meta-data class')\n",
    "\n",
    "for keys,values in dict_uniprot.items():\n",
    "    print(keys+':'+values)\n",
    "    #print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating csv file Uniprot_defense_related.csv\n",
    "### Meta-data of genes related with defense recovered from Uniprot DB\n",
    "Fist class defined: BAK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniprot DB recovery on: March-2020\n",
      "Meta-Data related to plant-defense genes was recovery\n",
      "Classes consulted:\n",
      "1.   BAK1:\n",
      "====================================\n",
      "Example of the class BAK1:\n"
     ]
    }
   ],
   "source": [
    "df_gene_meta_data = pd.read_csv(\n",
    "  '/home/cynthia/xtrome-main/Uniprot_defense_data/bak1_pd.tab',\n",
    "  sep = ' '\n",
    ")\n",
    "print(\"Uniprot DB recovery on: March-2020\")\n",
    "print(\"Meta-Data related to plant-defense genes was recovery\")\n",
    "print(\"Classes consulted:\")\n",
    "print(\"1.   BAK1:\")\n",
    "\n",
    "print('====================================')\n",
    "print(\"Example of the class BAK1:\")\n",
    "#df_gene_meta_data.head(5)\n",
    "\n",
    "#Fields-Heders correspond as follow:\n",
    "#Entry: Unique an stable ID\n",
    "#Entry_name: UniprotKB Entry (Mnemonic)\n",
    "#Gene_name: gene name primary\n",
    "#Lng: gene length\n",
    "#Protein_name: protein name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inserting column with static value in data frame for identify the class of the protein \n",
    "\n",
    "#df_gene_meta_data.insert(1,'Uniprot_Class', int, allowed_duplicates= False)\n",
    "df_gene_meta_data.insert(0,'Uniprot_Class', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_gene_meta_data.head(5)\n",
    "#df_gene_meta_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create and save the dataframe into defense_meta_data csv file\n",
    "df_gene_meta_data.to_csv('~/xtrome-main/Uniprot_defense_data/Defense_genes_metadata.csv', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append all records associated to each class pre-defined in the dict_uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory name: Uniprot_defense_data\\ in path /home/cynthia/xtrome-main/Uniprot_defense_data/\n",
      "\n",
      "Number of files to process: 13\n",
      "\n",
      "File names: ['fls2_pd.tab', 'mapks_pd.tab', 'tir_pd.tab', 'rlks_pd.tab', 'cc_pd.tab', 'cdpks_pd.tab', 'bak1_pd.tab', 'rks_pd.tab', 'prr_pd.tab', 'bik1_pd.tab', 'nb-lrr_pd.tab', 'raw_uniprot_files', 'Defense_genes_metadata.csv']\n"
     ]
    }
   ],
   "source": [
    "# Get the whole list of files in the directory (parameter sys.2) \n",
    "# base_dir: /home/cynthia/xtrome-main\n",
    "s_dir = '/home/cynthia/xtrome-main/Uniprot_defense_data/'     \n",
    "arr_fasta_f = os.listdir(s_dir)          # Create an array \n",
    "print('Directory name: Uniprot_defense_data\\ in path', s_dir)\n",
    "print('\\nNumber of files to process:', len(arr_fasta_f))\n",
    "print('\\nFile names:', arr_fasta_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 rcds appended to Defense_genes_metadata.csv. Uniprot class_name: FLS2 class# 5 File_name:fls2_pd.tab\n",
      "19 rcds appended to Defense_genes_metadata.csv. Uniprot class_name: MAPKS class# 6 File_name:mapks_pd.tab\n",
      "18 rcds appended to Defense_genes_metadata.csv. Uniprot class_name: TIR class# 11 File_name:tir_pd.tab\n",
      "1 rcds appended to Defense_genes_metadata.csv. Uniprot class_name: RLKS class# 10 File_name:rlks_pd.tab\n",
      "70 rcds appended to Defense_genes_metadata.csv. Uniprot class_name: CC class# 3 File_name:cc_pd.tab\n",
      "5 rcds appended to Defense_genes_metadata.csv. Uniprot class_name: CDPKS class# 4 File_name:cdpks_pd.tab\n",
      "10 rcds appended to Defense_genes_metadata.csv. Uniprot class_name: RKS class# 9 File_name:rks_pd.tab\n",
      "12 rcds appended to Defense_genes_metadata.csv. Uniprot class_name: PRR class# 8 File_name:prr_pd.tab\n",
      "5 rcds appended to Defense_genes_metadata.csv. Uniprot class_name: BIK1 class# 2 File_name:bik1_pd.tab\n",
      "16 rcds appended to Defense_genes_metadata.csv. Uniprot class_name: NB-LRR class# 7 File_name:nb-lrr_pd.tab\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/cynthia/xtrome-main/Uniprot_defense_data/raw_uniprot_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-19a399121b50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# load file downloaded ftom UniprotDB in csv format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdf_gene_meta_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfasta_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasta_f\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is a directory. The file will not be processed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xtrome_conda_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xtrome_conda_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xtrome_conda_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xtrome_conda_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1124\u001b[0m                     \u001b[0;34m'\"python-fwf\")'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 )\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xtrome_conda_env/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_comment_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m         f, handles = get_handle(\n\u001b[0m\u001b[1;32m   2265\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/xtrome_conda_env/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/home/cynthia/xtrome-main/Uniprot_defense_data/raw_uniprot_files'"
     ]
    }
   ],
   "source": [
    "# Parse the csv files in the directory to compose the Defense_genes_data file (Classes selected)\n",
    "\n",
    "for fasta_f in (arr_fasta_f):\n",
    "  \n",
    "    i_name_pos = fasta_f.rfind('_')\n",
    "    s_name_class = (fasta_f[0:i_name_pos])\n",
    "    s_name_class = s_name_class.upper()\n",
    "    \n",
    "    if s_name_class == 'BAK1': continue\n",
    "    # load file downloaded ftom UniprotDB in csv format \n",
    "    try:\n",
    "        df_gene_meta_data = pd.read_csv(s_dir+fasta_f, sep = ' ', engine='python')\n",
    "    except ValueError:\n",
    "        print(fasta_f + ' is a directory. The file will not be processed.')    \n",
    "   \n",
    "    try:\n",
    "        # parse and gets the 'key' class by 'value' in dict_uniprot\n",
    "        i_class = list(dict_uniprot.keys())[list(dict_uniprot.values()).index(s_name_class)]\n",
    "        # rename to columns to make them more intuitive\n",
    "        df_gene_meta_data.rename(columns = {'Entry.1':'Entry_name', \"name\": \"Gene_name\", \"Gene\": \"Lng\", \"names_(primary_)\": \"Protein_name\"}, inplace = True) \n",
    "         # insert the new meta-data column (see dictionary above)\n",
    "        df_gene_meta_data.insert(0,'Uniprot_Class', i_class)\n",
    "        # Append the results to the 'Defense_genes_data.csv' file   \n",
    "        df_gene_meta_data.to_csv(s_dir + 'Defense_genes_metadata.csv', mode='a', index=False, sep=',', header=False)    \n",
    "        print(str(len(df_gene_meta_data))+' rcds appended to Defense_genes_metadata.csv. Uniprot class_name: '+ s_name_class +' class# '+ str(i_class) + ' File_name:' + fasta_f)\n",
    "    except ValueError:\n",
    "        print(fasta_f + ' is not in dict_uniprot dictonary. The file will not be processed.')   \n",
    "        break\n",
    "    \n",
    "# Total: 217 Defense_genes_metadata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit on the exploration of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Uniprot raw data in csv format\n",
    "df_gene_meta_data = pd.read_csv(\n",
    "  '/home/cynthia/xtrome-main/Uniprot_defense_related/Defense_genes_metadata.csv',\n",
    "  sep = ','\n",
    ")\n",
    "df_gene_meta_data.head() \n",
    "df_gene_meta_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential classification based on several criterias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniprot DB recovery on: March-2020\n",
      "Criteria: filtered data by reviewed\n",
      "====================================\n",
      "\n",
      "Número de genes (primary_associated) en las clases BAK1, BIK1, CC, CDPKs, FLS2, MAPKs, NB-LRR, PRR, RKs, RLKs, TIR: 216 \n",
      "\n",
      "Agrupado por meta-clase:11\n",
      "Agrupado por identificador unico en bd (estable):189\n",
      "Agrupado por Protein_name:110\n",
      "Agrupado por Gene_name:179\n"
     ]
    }
   ],
   "source": [
    "# Overview of data\n",
    "\n",
    "# print('Data dimensions:', df_gene_meta_data.shape, '\\n')\n",
    "# print(df_gene_meta_data.dtypes)\n",
    "print(\"Uniprot DB recovery on: March-2020\")\n",
    "print(\"Criteria: filtered data by reviewed\")\n",
    "print('====================================\\n')\n",
    "print('Número de genes (primary_associated) en las clases BAK1, BIK1, CC, CDPKs, FLS2, MAPKs, NB-LRR, PRR, RKs, RLKs, TIR:', df_gene_meta_data['Uniprot_Class'].count(),'\\n')\n",
    "# print(len(df_gene_meta_data))\n",
    "\n",
    "\n",
    "# Based in Uniprot Class pre-defined\n",
    "df_grp = df_gene_meta_data.groupby(['Uniprot_Class'])\n",
    "i = str(len(df_grp))\n",
    "print('Agrupado por meta-clase:'+ i)\n",
    "\n",
    "# Based in the 'Entry' Class field pre-defined\n",
    "df_grp = df_gene_meta_data.groupby(['Entry'])\n",
    "i = str(len(df_grp))\n",
    "print('Agrupado por identificador unico en bd (estable):'+ i)\n",
    "\n",
    "# Based in the 'Protein_name' Class field pre-defined\n",
    "df_grp = df_gene_meta_data.groupby(['Protein_name'])\n",
    "i = str(len(df_grp))\n",
    "print('Agrupado por Protein_name:'+ i)\n",
    "\n",
    "# Based in the 'Gene_name' Class field pre-defined\n",
    "df_grp = df_gene_meta_data.groupby(['Gene_name'])\n",
    "i = str(len(df_grp))\n",
    "print('Agrupado por Gene_name:'+ i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to interpret this result:\n",
      "\n",
      "Basically you are showing a group by gene_name dataset. The # in the Uniprot_class column implies that exist n equal gene_names with different proteins definitions.\n",
      "\n",
      "Total members gruped by Gene_name class: Entry           11\n",
      "Entry_name      11\n",
      "Gene_name       11\n",
      "Lng             11\n",
      "Protein_name    11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Getting a protein description associated to the primary_gene name \n",
    "\n",
    "df_grp_sum = df_gene_meta_data.groupby(['Uniprot_Class']).sum()\n",
    "\n",
    "print('How to interpret this result:\\n')\n",
    "print('Basically you are showing a group by gene_name dataset. The # in the Uniprot_class column implies that exist n equal gene_names with different proteins definitions.\\n')\n",
    "print('Total members gruped by Gene_name class:', df_grp_sum.count())\n",
    "#df_grp_sum.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-87-2d914ce507e6>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-87-2d914ce507e6>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    for Uniprot_Class=='2' in df_grp:\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# For details about the grouped category\n",
    "# Ejm: based on the 'Uniprot_Class' Class field pre-defined\n",
    "df_grp = df_gene_meta_data.groupby(['Uniprot_Class'])\n",
    "i = str(len(df_grp))\n",
    "print('Agrupado por:'+ df_grp  + i)\n",
    "\n",
    "for Uniprot_Class=='2' in df_grp:\n",
    "    #print(Uniprot_Class)\n",
    "    print(Gene_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting a protein description associated to the primary_gene name \n",
    "\n",
    "df_grp2 = df_gene_meta_data.groupby(['Gene_name','Protein_name']).sum()\n",
    "\n",
    "print('How to interpret this result:\\n')\n",
    "print('Basically you are showing a group by gene_name & protein_name dataset. The # in the Uniprot_class column implies that exist n equal gene_names with the same protein definition.\\n')\n",
    "print('Total members after gruping class by gene_name & protein_name:', df_grp2.count())\n",
    "df_grp3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
